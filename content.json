{"posts":[{"title":"AXI","text":"","link":"/2025/09/14/AXI/"},{"title":"CUDA","text":"CUDA C++ Programming GuideBefore Diving into CUDA, let us answer the following questions: How GPUs are different than CPUs? What is a programming model? The intention of this post is to explain each chapter of the programming guide in a easy to understand way. The main concepts behind the CUDA programming model: Kernels Thread Hierarchy Memory Hierarchy Heterogeneous Programming Summary: In CUDA, each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors. References: CUDA-C-Programming-Guide [Book] Programming Massively Parallel Processors: A Hands-on Approach by Wen-mei W. Hwu, David B. Kirk, Izzat El Hajj.","link":"/2025/09/14/CUDA/"},{"title":"Clang","text":"","link":"/2025/09/14/Clang/"},{"title":"Dynamic Programming","text":"Introduction:Dynamic programming: is based on the concept of overlapping subproblems and optimal substructure. This is when the solution to a problem can be constructed from solutions to similar and smaller subproblems. The characteristics of dynamic programming problems: We need to find the maximum or minimum of something. We have to make a sequence of decisions that might look different depending on decisions we made previously. The framework for dynamic programming solution: Define the dynamic programming state.This is the result that gets reused in further computations.Example: dp(i, j) tells whether the substring composed of the ith to the jth characters of the input string is a palindrome or not. Identify the base cases.Example: Single letter substrings are palindromes dp(i,i) = true.Double letter substrings are palindromes if the same. dp(i,i+1) = true. Identify the optimal substructure.A string is considered a palindrome if: Its first and last characters are equal, and the rest of the string (excluding the boundary characters) is also a palindrome. Identify overlapping sub-problemsThe optimal substructure mentioned above ensures that the state for a string depends only on the state for a single substring. Find the answerExample: number of palindromes can be found by counting all states that evaluate true. Resources Dynamic Programming 1D (NeetCode) Dynamic Programming 2D (NeetCode) Dynamic Programming Introduction (Abdul Bari)","link":"/2025/09/14/Dynamic-Programming/"},{"title":"Git Basics","text":"","link":"/2024/08/12/Git/"},{"title":"GoogleTPU","text":"","link":"/2025/09/14/GoogleTPU/"},{"title":"LLVM Components","text":"OverviewLLVM is a modular toolchain for building compilers, linkers, and related tooling. Its core idea is a common, language‑independent Intermediate Representation (LLVM IR) plus a rich library of reusable components for optimization and code generation. This blog introduces the major building blocks and how they fit together. Front Ends Clang: C, C++, Objective‑C, CUDA/HIP, OpenMP; lowers source into LLVM IR. Flang: Fortran front end built on the LLVM ecosystem. Others: Rust, Swift, Julia, Zig, and many more use LLVM as a backend. Front ends typically perform parsing, semantic analysis, and lowering to LLVM IR (SSA form). LLVM IR and Bitcode LLVM IR: Typed, Static Single Assignment (SSA) intermediate form organized as Module → Functions → Basic Blocks → Instructions. Text vs Bitcode: IR can be stored as human‑readable .ll or binary .bc (bitcode) for fast loading and LTO. Verifier: Validates structural correctness of IR. Passes and Optimizer Passes: Modular transformations or analyses (e.g., InstCombine, GVN, SCCP, Dead Code Elim, Inliner). Pass Managers: Orchestrate pass pipelines (function, module, CGSCC, loop levels; new PM is default). Vectorization: Loop Vectorize, SLP Vectorize. IPO/LTO: Inter‑procedural optimizations; LTO and ThinLTO optimize across translation units using bitcode. Code Generation (Back End) Instruction Selection: Maps IR to target instructions (SelectionDAG or GlobalISel on newer targets). Register Allocation: Assigns virtual registers to physical (Greedy, PBQP, etc.). Scheduling &amp; Peepholes: Reorder and tighten instruction streams. Prologue/Epilogue &amp; Frame Lowering: Stack frame management and calling convention lowering. Emission: Produces assembly, object files, or machine code buffers. Target Descriptions TableGen: Declarative target specs (instructions, registers, patterns) that generate C++ code. Subtarget Features: CPU/arch variants (e.g., x86-64, skylake, avx2) toggled via attributes/flags. TargetLowering: Hooks controlling how IR ops lower to target instructions. MC Layer (Assembler/Disassembler/Object) Assembler/Disassembler: Target‑independent framework for parsing/printing machine code. Object Emission: Writes ELF/COFF/Mach‑O with relocations and metadata. Tools built on MC: llvm-objdump, llvm-objcopy, llvm-readelf, llvm-nm, etc. Linkers and LTO lld: LLVM’s high‑performance linker (ELF/COFF/Mach‑O flavors). Gold/ld plugins: Enable (Thin)LTO by passing LLVM bitcode to the optimizer at link time. Runtime and C++ Libraries compiler‑rt: Builtins and sanitizers (ASan, UBSan, TSan, etc.). libc++ / libc++abi / libunwind: C++ standard library, ABI, and unwinder. OpenMP (libomp): Runtime for OpenMP offload and threading. Key Developer Tools clang: Front end driver for C/C++/Obj‑C. opt: Run and experiment with optimization passes on IR. llc: Lower IR to native assembly/object. llvm-as / llvm-dis: IR assembler/disassembler (.ll ↔ .bc). tblgen: Processes TableGen descriptions for targets/diagnostics. Typical Pipeline (C → x86‑64) Parse &amp; Lower: Clang parses C/C++ and lowers to LLVM IR. Optimize: opt/Clang pass pipeline runs analyses and transforms (inline, simplify, vectorize…). Codegen: Instruction selection, register allocation, scheduling. Object/Link: Emit .o, link with lld (optionally ThinLTO), produce executable. Where to Explore Next Browse IR (clang -S -emit-llvm foo.c -o foo.ll) and run passes (opt -passes=...). Compare back ends (llc -mtriple=) and try feature flags (e.g., -mattr=+avx2). Inspect objects with llvm-objdump -d and llvm-readelf -S. This overview should give you a map of the LLVM landscape—front ends generate IR, passes optimize it, and back ends turn it into efficient machine code, all powered by reusable libraries and tools.","link":"/2025/08/12/LLVM/"},{"title":"Lit","text":"","link":"/2025/09/14/Lit/"},{"title":"MLIR","text":"","link":"/2025/09/14/MLIR/"},{"title":"NPU","text":"","link":"/2025/09/14/NPUs/"},{"title":"ROCM","text":"","link":"/2025/09/14/ROCM/"},{"title":"Torch-mlir","text":"","link":"/2025/09/14/Torch-mlir/"},{"title":"pyTorch","text":"","link":"/2025/09/14/pyTorch/"}],"tags":[{"name":"Software Engineering","slug":"Software-Engineering","link":"/tags/Software-Engineering/"},{"name":"Compiler","slug":"Compiler","link":"/tags/Compiler/"}],"categories":[{"name":"Tutorials","slug":"Tutorials","link":"/categories/Tutorials/"}],"pages":[{"title":"Murad Qasaimeh","text":"AboutI’m Murad Qasaimeh. I build AI compilers and machine learning systems.I’m intrested about turning research into fast, production‑ready software. AI compilers and graph optimizations. Performance engineering and acceleration. ML systems and developer tooling. Explore Projects Blog Tutorials Publications Curriculum Vitae Tags Connect LinkedIn GitHub Google Scholar","link":"/index.html"},{"title":"Projects","text":"List of projects: Structured Pruning for Deep Neural Networks (DNNs): Implemented magnitude-based structured weight pruning method to improve the performance of its hardware implementation, by keeping number of NNZ values per channel fixed to help load balancing. (Python, Tensorflow). CUDA Implementation of Sparse DNNs: Implemented a high-performance CUDA implementation of structurly sparse DNN and compared its performance with NVIDIA libraries for dense and sparse DNNs: (cuDNN, cuBLAS and cuSPARSE). (C++, CUDA). Benchmarking Vision Kernels and Neural Network Inference Accelerators on Embedded Platforms [1]: Conducted comprehensive benchmarks of accuracy, run-time, and energy efficiency of a wide range of vision kernels and neural networks on multiple embedded platforms: ARM57 CPU, Nvidia Jetson TX2 GPU and Xilinx ZCU102 FPGA. (xFOpenCV, OpenCV, VisionWorks)","link":"/Projects/index.html"},{"title":"Curriculum","text":"CareerMTS Software Engineer, AMD (Full‑time) Location: San Jose, California, United States Dates: Aug 2022 – Present Highlights: Enabling development of compilers, simulators, and performance analysis tools for AI/ML engines. Developing an end‑to‑end compiler for ML frameworks targeting AMD AIE devices using LLVM and MLIR. Lead Software Engineer, Cadence Design Systems (Full‑time) Location: San Jose, California, United States Dates: Sep 2020 – Jul 2022 (1 yr 11 mos) Research Assistant, Iowa State University Location: Ames, Iowa Dates: Sep 2015 – Jun 2020 (4 yrs 10 mos) Research Engineer Intern, Xilinx Location: San Jose, California Dates: May 2018 – Nov 2018 (7 mos) Education Iowa State University – Ames, Iowa PhD in Electrical and Computer Engineering, GPA: 3.85 (2015 – 2020) Thesis: Efficient Processing of Computer Vision and Deep Learning on FPGAs American University of Sharjah – Sharjah, UAE Master in Electrical and Computer Engineering, GPA: 3.82 (2012 – 2014) Thesis: An FPGA-based Parallel Hardware Architecture for Real-time Image Classification Jordan University of Science and Technology – Irbid, Jordan Bachelor of Science in Computer Engineering, GPA: 85.7/100 (2006 – 2012) Senior Design Project: Indoor Mobile Robot Localization and Navigation SkillsProgramming LanguageI often program using C/C++, CUDA, CMake, and Python. I also have experience in C#, Java at least one large project with each. Machine Learning and Deep Learning Natural Language Processing Computer Vision Speech Processing Statistical Methods Optimization Methods","link":"/Curriculum/index.html"},{"title":"PUBLICATIONS","text":"Publications Benchmarking vision kernels and neural network inference accelerators on embedded platforms - M Qasaimeh, K Denolf, A Khodamoradi, M Blott, J Lo, L Halder, K Vissers, … - Journal of Systems Architecture 113, 101896 - 2021FPGA CPU GPU Embedded Systems Neural Networks Benchmarking An efficient hardware architecture for sparse convolution using linear feedback shift registers - M Qasaimeh, J Zambreno, PH Jones - 2021 IEEE 32nd International Conference on Application-specific Systems … - 2021FPGA Sparse Convolution Embedded Systems Efficient processing of vision kernels and deep neural networks on reconfigurable computing architectures - M Qasaimeh - Iowa State University - 2020Reconfigurable Computing Deep Learning Computer Vision Comparing energy efficiency of CPU, GPU and FPGA implementations for vision kernels - M Qasaimeh, K Denolf, J Lo, K Vissers, J Zambreno, PH Jones - 2019 IEEE international conference on embedded software and systems (ICESS), 1-8 - 2019Energy Efficiency Heterogeneous Computing Computer Vision Analyzing the energy-efficiency of vision kernels on embedded CPU, GPU and FPGA platforms - M Qasaimeh, J Zambreno, PH Jones, K Denolf, J Lo, K Vissers - 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom … - 2019Energy Efficiency Heterogeneous Computing FPGA A novel SIFT architecture and ASIC implementation for real time SOC application - M Qasaimeh, H Saleh, B Mohammad, T Tekeste, M Ismail - Analog Integrated Circuits and Signal Processing 99 (2), 325-338 - 2019Feature Extraction ASIC Design Computer Vision A runtime configurable hardware architecture for computing histogram-based feature descriptors - M Qasaimeh, J Zambreno, PH Jones - 2018 28th International Conference on Field Programmable Logic and … - 2018FPGA Feature Extraction Reconfigurable Computing Recent advances in feature extraction and description algorithms: Hardware designs and algorithmic derivatives - EN Salahat, M Qasaimeh - Handbook of Research on Advanced Concepts in Real-Time Image and Video … - 2018Feature Extraction Computer Vision Hardware Acceleration Real-time image and video processing using high-level synthesis (hls) - M Qasaimeh, EN Salahat - Handbook of Research On Advanced Concepts in Real-Time Image and Video … - 2018High-Level Synthesis Image Processing Real-Time Systems Mohammad K. Al-Sharman, Murad Qasaimeh, Bara J. Emran, Mohammad A. Jaradat, and - MA Al-Jarrah - Sensors for Diagnostics and Monitoring, 79 - 2018 Sensors Diagnostics Embedded Systems Optical Flow Sensing and Its Precision Vertical Landing Applications - MK Al-Sharman, M Qasaimeh, BJ Emran, MA Jaradat, MA Al-Jarrah - Sensors for Diagnostics and Monitoring, 301-328 - 2018 Optical Flow UAV Navigation Sensors Recent advances in features extraction and description algorithms: A comprehensive survey - E Salahat, M Qasaimeh - 2017 IEEE international conference on industrial technology (ICIT), 1059-1063 - 2017 Feature Extraction Computer Vision Industrial Automation Unified analytical modeling of the error rates and the ergodic channel capacity in eta-mu generalized fading channels with integer mu and maximal ratio combining receiver - E Salahat, M Qasaimeh - 2017 IEEE International Conference on Industrial Technology (ICIT), 1217-1221 - 2017 Wireless Communications Channel Modeling Mathematical Analysis A modified sliding window architecture for efficient bram resource utilization - M Qasaimeh, J Zambreno, PH Jones - 2017 IEEE International Parallel and Distributed Processing Symposium … - 2017 Sliding Window BRAM Optimization FPGA Handbook of Research on Advanced Concepts in Real-Time Image and Video Processing - MI Anwar, A Khosla, R Kapoor - IGI Global - 2017 Image Processing Real-Time Systems Academic Publishing ZigBee-based irrigation system for home gardens - AR Al-Ali, M Qasaimeh, M Al-Mardini, S Radder, IA Zualkernan - 2015 International Conference on Communications, Signal Processing, and … - 2015 ZigBee Agritech Embedded Systems FPGA-based parallel hardware architecture for real-time image classification - M Qasaimeh, A Sagahyroon, T Shanableh - IEEE Transactions on Computational Imaging 1 (1), 56-70 - 2015 FPGA Computer Vision Object Classification Applying Monte Carlo simulation to biomedical literature to approximate genetic network - R Al-Dalky, K Taha, D Al Homouz, M Qasaimeh - IEEE/ACM transactions on computational biology and bioinformatics 13 (3 … - 2015 Monte Carlo Bioinformatics Genetic Networks A parallel hardware architecture for Scale Invariant Feature Transform (SIFT) - M Qasaimeh, A Sagahyroon, T Shanableh - 2014 International Conference on Multimedia Computing and Systems (ICMCS … - 2014 FPGA Feature Extraction Computer Vision","link":"/Publications/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"Tutorials","text":"Quick links to tutorial categories: AI Compilers: /categories/AI-Compilers/ LeetCode: /categories/LeetCode/ Hardware Architecture: /categories/Hardware-Architecture/","link":"/tutorials/index.html"}]}